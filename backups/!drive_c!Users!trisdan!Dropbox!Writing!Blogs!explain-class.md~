# Speculating on Steve Yegge's Other Classification Decisions
This is a follow-up to "Why Steve Yegge Calls Clojure Conservative", where I try to dig into why he classified the other languages in his list as he did. It's mostly for fun; the only possible use I could see for this is to try and understand why he classified your favorite language the way he did.

Two caveats: just because I try to understand why he classified a language a certain way doesn't mean I agree with his classification. In fact, I'm going to point out where I disagree with his classifications, even though you could argue that, as the inventor of this framework, he understands it better than any of us and we haven't got any basis to dispute his classifications. As I said in the last post, I'm more software-conservative than he is, so that will color some of my opinions. 

Second, I am not an expert in all of these languages. Not even close. Some of them, I only know by reputation and have never even written a "Hello world" in the language. Others, I've only gotten as far as "Hello world". So if you disagree with my explanations, comment! Unlike Steve, I still read comments.

## Batshit Liberal: Assembly Language.
Assembly language is the champion of giving the programmer control. It does not offer any protection at all from mistakes. It basically lets you do *anything*.

My assembly language-loving professor that I mentioned last time liked to tell us a story about a student of his who got printing working by writing an assembly program that bypassed the OS and threw bits directly at the address where the printer port was. He also told us a story about a time his team implemented something that, in retrospect, sounds a lot like lambdas, by loading code into the data section of the assembly program, and later directly manipulating the program counter to point into the data section and execute it.

These kinds of things are just not possible in Java and Python, not without some kind of library. Otherwise people could have added lambdas to Java years ago, and they would be horribly broken, and we'd have fifty implementations with slightly different interfaces and different bugs. I'm not even sure you could do things like this in C or C++ without writing some kind of assembly language library.

Assembly language is too liberal even for Steve Yegge. He says in one of his essays that his first company used assembly language for everything, and he attributes their fall to that, at least in part.

## Extremist Liberal: Ruby, Perl, PHP, shell script.
I have to admit I don't really understand why Ruby is more liberal than Python, according to Steve. Unlike Python, Ruby has non-public visibility modifiers, which Steve lists as conservative. It does have more advanced metaprogramming than Python, but I attribute that more to being able to look back at what was lacking in Python, or looking more broadly at what was cool in Smalltalk and other languages, and adding those to Ruby, than to Python intentionally not including those features. I will agree that Ruby's attitude to lambdas is a lot more liberal than Python's; Ruby includes lambdas (in the form of blocks) as an essential part of the language, whereas in Python, Guido wouldn't add them until there were already fifty incompatible versions that people had hacked together themselves. Python is a bit less DSL-happy than Ruby, and the language's syntax (with significant whitespace) makes it a little harder to build DSLs on top of it. It's possible that if I knew Ruby better (and Python too), I would be able to understand this classification more.

I also don't quite understand why PHP is more liberal than Javascript. Both have rafts of automatic type conversions. Both have eval, and first-class functions, and essentially no namespacing mechanism (PHP sort of has one, but the standard library doesn't use it. Javascript doesn't have one, but programmers use closures and objects to simulate them). PHP does do some of the implicit global variable thing that Perl and shell like, which Javascript doesn't. But the newer PHP code I've seen is pretty object-oriented and reasonably explicit.

But Perl and shell, from what little I know of them, are certainly more liberal than Python and Javascript. Perl loves implicit side effects; the Perl community calls this "Do What I Mean", and from what I can tell, a big part of becoming a proficient Perl programmer is memorizing what kinds of implicit side effects you can capitalize on in any given situation. Skilled Perl programmers can make their code tiny because they can pack lots of extra actions into less code by taking advantage of "Do What I Mean". Shell is similar. Both of them love cartoon swear-word syntax and insanely specialized operators. Shell is also liberal in that it has no type system; everything in shell is a string. Perl kind of has one, with its sigils. Even the Perl community has some standards; the Perl interpreter has an option that requires variables to be declared before use, among other checks, and the community advises that this option always be turned on.

You often see the most awful Perl and shell code around when people want to dump on them, but I've also seen some pretty nice Perl code. The command line tool Wordgen, for instance, has pretty nice Perl code, and the Perl samples in *Mastering Regular Expressions* aren't too bad. You do still have to learn some of the implicit rules (*Mastering Regular Expressions* makes heavy use of implicit global variables), but it's not that bad. I've never used Perl personally, but I have used shell, and it's incredibly useful, so even though these languages are a little more liberal than I usually prefer, I can see why people like them so much.

## Hardcore Liberal: Javascript, Visual Basic, Lua.
I've never used Lua. It sounds pretty liberal from what I know of it, but that's not much.

Javascript definitely feels very liberal. The prototype system feels a lot more loose and dynamic than class-based inheritance. You can create new families of objects at runtime by modifying the prototypes, which you can't do in a system like Java's&mdash;the inheritance hierarchy has to be decided at compile time. Javascript also does tons of implicit type conversions, including automatic stringification, which Steve lists as liberal.

I think maybe Steve used an older version of Visual Basic which was more like VBA or VBScript and based his classification off of that. I used Visual Basic .Net 2008, and it felt almost indistinguishable from Java, given the static type system with everything declared and annotated, and the heavy emphasis on object-oriented programming with data hiding. The main differences from Java that I noticed were that VB.Net has standalone functions, like C++, and that it has some of those nice C# features that C# people are always bragging about, like delegates, properties, lambdas, and LINQ (which reminded me of a Python list comprehension, although apparently it's supposed to feel like SQL). 

## Liberal: Python, Common Lisp, Smalltalk.
I've never used Smalltalk, but it's dynamically typed and has a precursor to Ruby's <code>method_missing</code>. It's apparently similar to the Io language, but with classes instead of prototypes.

Python has eval, metaprogramming, decorators (which are sort of like macros, kind of), runtime type inference, optional parameters, somewhat extensible syntax (operator overloading), and mixed-type collections. It's dynamically typed, and its classes have no nonpublic access specifiers (there are various ways to hida data if you want to, but they're all kind of a pain, and none are as easy as slapping <code>private</code> on something in Java. That pain is the language telling you it doesn't like that).

On the other hand, Python enforces whitespace conventions, and it has a strong type system that doesn't do any automatic conversions for you. On that point, it's even more conservative than Java; even Java will just give you the string <code>"val: 3"</code> if you type <code>"val: " + 3</code>, but Python treats this as an error; you have to explicitly call the <code>str</code> function on 3 before you can stick it to a string. Python will more or less move between numeric types as you'd expect, but it doesn't do much for you when it comes to type conversion. Even the Zen of Python says "Explicit is better than implicit", which is a conservative attitude. Pythonistas also seem more concerned with performance than Rubyists or Perlies; when I first started learning the language, almost every source I encountered tried to make the case that Python's performance could rival C's if you squinted at the numbers the right way. It didn't work; Python still got pegged as painfully slow, which isn't really fair, but that's how it is. Ruby is generally regarded as even slower, so we're in good company.

Common Lisp actually feels pretty conservative in a lot of ways, but I guess as Lisps go, it's on the liberal side. It does have user-defined reader macros (extensible syntax) alongside the standard Lisp macros. And of the three Lisp dialects on this list (CL, Scheme, Clojureâ€”I'm specifically ignoring Emacs Lisp since it wasn't on the list), Common Lisp does seem to give you the most ways to give the finger to pure functional programming. It has functions like <code>rplaca</code> and <code>rplacd</code> that let you mutate the car and cdr of a list; its <code>setq</code> lets you reassign variables more or less as you please; and it has heavy duty support for imperative and object-oriented programming, in the form of <code>progn</code>, <code>do</code>, and CLOS. In my programming languages class at university, we used Common Lisp as the functional language, but the professor had a list of EVIL functions that were outlawed, which of course included <code>setq</code>, <code>rplaca</code>, <code>rplacd</code>, <code>do</code>, and <code>progn</code>. He did have us use <code>do</code> and <code>progn</code> so we could practice implementing a simple looping function using Schemey car-cdr recursion, higher order functions (mapcar), and the imperative-style loops. But for the main bulk of the assignment, the imperative escape hatches were forbidden.

## Moderate Liberal: C, Objective-C, Scheme.
I've only done "Hello world" in Scheme, but I understand it puts up with far fewer imperative escape hatches than Common Lisp, and goes further towards pure functional programming. It clearly cares about isolating mutable state, since it began the convention of using ! to mark functions that have side-effects (which Clojure sort of copies, when it feels like it, and which Ruby also uses).

I've never worked with Objective-C, but as I understand it, it was an attempt to incorporate Smalltalk-style OOP into C, where C++ was using Modula-3-style OOP. Since Smalltalk is pretty liberal, it makes sense that Objective-C would be too.

One thing C is definitely not concerned with is protecting the programmer from mistakes. It has two incredibly error-prone features: pointers, and preprocessor macros. Since C is such a small language, there are many things you just can't accomplish without using pointers or preprocessor macros (or both, God help you). C is a language for people like Ken Thompson, who was just cruising along, acing all his college classes, and woke up one day to find that he was suddenly in graduate school.

C's type system is sort of the opposite of Python's. Python doesn't make you tag anything with a type, but behind the scenes, it has its own very definite ideas of what type everything is, and if you have your own ideas, they'd better fit in with Python's. C makes you tag everything, but then it proceeds to pretty much ignore the tags for almost every purpose, and any time it doesn't ignore them, you can probably just cast it into a void pointer or an array of unsigned characters and do whatever you want with it. Where Javascript and PHP have implicit conversions, C has no conversions, because it was treating everything as having no type to begin with. When you declared the type, C said "Yeah, yeah" and then proceeded to turn it into whatever it wanted at the time.

## Moderate-conservative: C++, Java, C#, D, Go.
I've never worked with Go, D, or C# (I've done "Hello world" in C#). But as far as I know, they are quite similar to C++ and Java in most ways.

C++ and Java are moderate-conservative I think mostly because of their type systems. They make you tag everything to death. Newer versions somewhat alleviate this with features like C++'s auto keyword and Java's diamond operator, but C++ and Java programs are still almost 50% type annotation keywords, and in some lines it's more like 80% consumed with type annotations.

C++ and Java are also pretty strict about enforcing types. They both have some implicit type conversions, like Java's automatic stringification that I mentioned above. And they use giant inheritance hierarchies with complicated rules to extend the type system, in contrast to the kind of dynamic, loose, behavioral extensions you get with Javascript's prototype system. On the other hand, they both have escape hatches; Java has unsafe casts (which are checked at runtime), and C++ lets you do all the crazy stuff C does, more or less, with void pointers, arrays of unsigned char, and preprocessor macros.

## Conservative: Clojure, Erlang, Pascal.
I explained Clojure and Erlang a little in the last post. Both of them are much more purely functional than Common Lisp or Scheme, with immutable variables and mainly pure functions. Both do allow imperative escape hatches; you can use Erlang's actors a lot like Smalltalk objects, and Clojure has mutable state in the form of atoms and refs, as well as the vaguely object-oriented protocols and records. Also, unlike Haskell, they allow side effects; printing to stdout in Clojure and Erlang is achieved by a function that prints to the console, by side effect. Still, neither of them really give you good ways to create your own side-effecting functions; functions with side effects are mostly built-ins or make use of built-ins. (Clojure lets you use Java arrays, and you can write Java classes and call them from Clojure, but it's clear in both cases that it's dispreferred.)

Pascal is well known for having a much stronger type system than C. I haven't worked with it, but I studied the type system at university a little bit. It reminded me a lot of Java's type system, but without the escape hatches (like unsafe casts). And the language doesn't give you a lot of building blocks, so far as I know; it's pretty much all standalone functions, much like C.

## Hardcore Conservative: Scala, Ada, OCaml, Eiffel.
The only one of these languages that I've used is Scala. As far as I know, Ada is similar to Pascal, but with more features and an even stronger type system. You can actually define new data types that only accept numbers in a limited range in Ada.

OCaml is sort of like ML, but multi-paradigm; it allows object-oriented programming to seep in, but it retains the functional bias of ML.

Eiffel pioneered Design by Contract, where a methods preconditions and postconditions are enumerated exhaustively.

I thought Scala was a pretty cool language, but I do have to agree that its type system is super complex. In some ways, Scala is more liberal than its cousin Clojure; it's a multiparadigm language (object-oriented with strong functional tendencies), and it allows mutable variables. If you declare something with <code>val</code>, it becomes immutable and can only be assigned once. If you declare it with <code>var</code>, you can reassign it, just like any Java variable. So Scala is less purely functional than Clojure, and it allows mutable state and objects.

But Scala's type system is extremely strong. Scala uses type inference, so it's not as annotation-oriented as Java, but it lacks Java's runtime type system escape hatches. Its incredibly complex type system is a way to plug the holes in Java's system that necessitated those escape hatches to begin with; Scala tries to make everything statically checkable at compile time. And it is further down the path to pure functional programming than Java, or even Scheme.

## Extremist Conservative: Haskell, SML.
I've only done "Hello world" in these two, but I think I can say one word to convince you why Steve classified Haskell like this: monads.

Haskell's designers were so scared of <code>print(22)</code> printing 22â€”my God, man! Can you ever *prove* that it should print 22? Can you *prove* that it just prints 22, and nothing else, like, say, urinating on your lawn? Can you model it with the lambda calculus and run it through an automated proof assistant to check your proof, and then have an automated proof assistant assistant check the check on the proof? NO? Too dangerous! Haskell's designers were so scared of this that they came up with monads so they could at least separate provable stuff from voodoo gobbledegook.

All joking aside, Haskell is the ultimate evolution of pure functional programming and strong type systems: it has a type system so strong it once beat Hercules in a wrestling match, and it's so purely functional that even the Virgin Mary said "That sure is one pure language". Both of these make it extremist conservative, because strong static typing is meant to protect programmers from errors, and pure functional languages are restrictive rather than permissive.

ML, which I've encountered in reading *Purely Functional Data Structures*, is similar: it has a very strong type system, and it's allergic to side effects. I don't know if it has monads; IO didn't come up in that book much.

I actually want to try working with these languages more, though. I tried Scala and found it a bit too complex for my taste, but I actually like the look of Haskell, even though I'm not into monads. I don't like type annotations, but Haskell's inference seems to pretty much take care of that. I'm neither as smart nor as software-liberal as Steve, so I'm curious to know if Haskell is something I might like. 
